---
mermaid: true
mathjax: true
title: Andrew's GitHub Webpage
---





## Welcome to My GitHub Page

This is a place to show off some of the amazing projects I have been working on at the College of William and Mary!!!

You are able to see my repository [here](https://github.com/achoi1107/data440_capstone_homework) in case you want to take a look at any code or other types of content. 

## Wonderful Word Cloud on Machine Learning 

Testing out showing images on the website with this beautiful word cloud:

<img src="./images/word cloud.jpg" width="500" height="500" alt="hi" class="inline"/>

### Project 1

This project focuses on designing and implementing a custom class for Locally Weighted Regression (LWR), capable of handling multiple features and incorporating both training and testing data. The objective is to apply this implementation to a real-world dataset and evaluate its performance through 10-fold cross-validation to compute the mean square error (MSE).

Link to [project 1](./homework1.md)


### Project 2

In this project, I will develop a class that implements the Gradient Boosting concept using the locally weighted regression method (Lowess), incorporating essential functionality such as fitting the model, checking if it is fitted, and making predictions with a user-defined number of boosting steps. I plan to apply this model to real datasets for regression tasks, utilizing 10-fold cross-validation to evaluate performance while comparing the effects of different scalers—StandardScaler, MinMaxScaler, and QuantileScaler—on the results. Specifically, I will analyze the Concrete dataset to determine hyperparameters that yield lower Mean Squared Errors (MSE) than those produced by the eXtream Gradient Boosting library. Additionally, I will implement a version of Locally Weighted Logistic Regression (LWLR) and compare its performance on the Iris dataset with a reference implementation, aiming to assess the effectiveness of my custom LWLR in classification tasks.

Link to [project 2](./homework2.md)


### Project 3

For this project, I will develop a custom PyTorch class that implements SCAD (Smoothly Clipped Absolute Deviation) regularization for linear models. My goal is to explore how SCAD performs in variable selection by penalizing large coefficients, and I will test this on a real dataset to determine feature importance. Additionally, I will generate 200 simulated datasets with a strong correlation structure (around 0.9) to compare SCAD against ElasticNet and SqrtLasso, evaluating which method best approximates an ideal solution represented by a designed "betastar" with a chosen sparsity pattern. Finally, I will apply these methods to the Concrete dataset, which includes quadratic interaction terms, to identify the ideal model size (number of non-zero coefficients) and compute the cross-validated mean square error (MSE). Through this process, I aim to determine the most effective regularization technique for feature selection and model performance.

Link to [project 3](./homework3.md) 

## Future Projects 

Not here yet...